{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習時間"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "請觀看李宏毅教授以神奇寶貝進化 CP 值預測的範例，解說何謂機器學習與過擬合。並回答以下問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[youtube](https://www.youtube.com/watch?v=fegAeph9UaA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias-Variance Tradeoff\n",
    "In statistics and machine learning, the bias–variance tradeoff is the property of a set of predictive models whereby models with a lower bias in parameter estimation have a higher variance of the parameter estimates across samples, and vice versa.\n",
    "\n",
    "- Low Bias: \n",
    "![Low bias](http://i1.bangqu.com/j/news/20180123/5bc93e9fbee64d909795afa4f52b16dd.jpeg)\n",
    "\n",
    "- High Bias: \n",
    "![High bias](http://i1.bangqu.com/j/news/20180123/357b5ba39ad042aa9d1a96eed5c2e75d.png)\n",
    "\n",
    "### Learning Curve\n",
    "A learning curve is a relationship of the duration or the degree of effort invested in learning and experience with the resulting progress, considered as an exploratory discovery process.\n",
    "\n",
    "![Learning Curve](http://i1.bangqu.com/j/news/20180123/89edbff69a834fc6a09357730be3d37b.png)\n",
    "![Learning Curve](http://i1.bangqu.com/j/news/20180123/bfe60571bf784dd7a43c4f44c49e3b28.png)\n",
    "![Learning Curve](http://i1.bangqu.com/j/news/20180123/02dbaf3bd18a47098efc09d9e40295f8.png)\n",
    "\n",
    "Reference from [here](http://bangqu.com/yjB839.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 模型的泛化能力 (generalization) 是指什麼？ \n",
    "Generalization refers to your model's ability to adapt properly to new, previously unseen data, drawn from the same distribution as the one used to create the model.\n",
    "\n",
    "### 2. 分類問題與回歸問題分別可用的目標函數有哪些？\n",
    "\n",
    "- Regression Loss Functions\n",
    " - Mean Squared Error Loss\n",
    " - Mean Squared Logarithmic Error Loss\n",
    " - Mean Absolute Error Loss\n",
    "\n",
    "- Binary Classification Loss Functions\n",
    " - Binary Cross-Entropy\n",
    " - Hinge Loss\n",
    " - Squared Hinge Loss\n",
    "\n",
    "- Multi-Class Classification Loss Functions\n",
    " - Multi-Class Cross-Entropy Loss\n",
    " - Sparse Multiclass Cross-Entropy Loss\n",
    " - Kullback Leibler Divergence Loss\n",
    " \n",
    "Reference from [here](https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
