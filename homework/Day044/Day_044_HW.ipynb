{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [作業重點]\n",
    "確保你了解隨機森林模型中每個超參數的意義，並觀察調整超參數對結果的影響"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業\n",
    "\n",
    "1. 試著調整 RandomForestClassifier(...) 中的參數，並觀察是否會改變結果？\n",
    "2. 改用其他資料集 (boston, wine)，並與回歸模型與決策樹的結果進行比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(model, x_test, y_test):\n",
    "    print(\"test accuracy: \", round(model.score(x_test, y_test), 4))\n",
    "    print(\"confusion matrix: \\n\", confusion_matrix(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.25, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of estimators: 100 | Max depth: 5 | Accuracy: 0.9736842105263158\n",
      "# of estimators: 100 | Max depth: 6 | Accuracy: 0.9473684210526315\n",
      "# of estimators: 100 | Max depth: 7 | Accuracy: 0.9736842105263158\n",
      "# of estimators: 100 | Max depth: 8 | Accuracy: 0.9736842105263158\n",
      "# of estimators: 200 | Max depth: 5 | Accuracy: 0.9736842105263158\n",
      "# of estimators: 200 | Max depth: 6 | Accuracy: 0.9736842105263158\n",
      "# of estimators: 200 | Max depth: 7 | Accuracy: 0.9736842105263158\n",
      "# of estimators: 200 | Max depth: 8 | Accuracy: 0.9736842105263158\n",
      "# of estimators: 300 | Max depth: 5 | Accuracy: 0.9736842105263158\n",
      "# of estimators: 300 | Max depth: 6 | Accuracy: 0.9736842105263158\n",
      "# of estimators: 300 | Max depth: 7 | Accuracy: 0.9736842105263158\n",
      "# of estimators: 300 | Max depth: 8 | Accuracy: 0.9736842105263158\n",
      "# of estimators: 400 | Max depth: 5 | Accuracy: 0.9736842105263158\n",
      "# of estimators: 400 | Max depth: 6 | Accuracy: 0.9736842105263158\n",
      "# of estimators: 400 | Max depth: 7 | Accuracy: 0.9736842105263158\n",
      "# of estimators: 400 | Max depth: 8 | Accuracy: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "for num_est in [100, 200, 300, 400]:\n",
    "    for max_depth in [5, 6, 7, 8]:\n",
    "        clf = RandomForestClassifier(\n",
    "            n_estimators=num_est, \n",
    "            max_depth=max_depth, \n",
    "            bootstrap=True)\n",
    "        clf.fit(x_train, y_train)\n",
    "        y_pred = clf.predict(x_test)\n",
    "        acc = metrics.accuracy_score(y_test, y_pred)\n",
    "        print(\"# of estimators: {} | Max depth: {} | Accuracy: {}\".format(num_est, max_depth, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  0.9737\n",
      "confusion matrix: \n",
      " [[18  0  0]\n",
      " [ 0  7  1]\n",
      " [ 0  0 12]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done   7 out of  25 | elapsed:    1.4s remaining:    3.7s\n",
      "[Parallel(n_jobs=16)]: Done  20 out of  25 | elapsed:    1.5s remaining:    0.3s\n",
      "[Parallel(n_jobs=16)]: Done  25 out of  25 | elapsed:    1.5s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "xgb = XGBClassifier(random_state=17, verbosity=0)\n",
    "params = { \n",
    "    'min_child_weight': [1, 5, 10],\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'max_depth': [5, 10, 15, 20]\n",
    "}\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=17)\n",
    "random_search = RandomizedSearchCV(\n",
    "    xgb, \n",
    "    param_distributions=params, \n",
    "    n_iter=5, \n",
    "    scoring=\"f1_weighted\", \n",
    "    n_jobs=multiprocessing.cpu_count(), \n",
    "    cv=skf.split(x_train, y_train), \n",
    "    verbose=2, \n",
    "    random_state=17)\n",
    "random_search.fit(x_train, y_train)\n",
    "xgb = random_search.best_estimator_\n",
    "performance(xgb, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()\n",
    "x_train, x_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size=0.25, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalties: 1 | MSE: 42.670029732855795\n",
      "Penalties: 2 | MSE: 31.870269694362477\n",
      "Penalties: 3 | MSE: 27.355687749608045\n",
      "Penalties: 4 | MSE: 25.013394160606925\n",
      "Penalties: 5 | MSE: 23.04952632025864\n",
      "Penalties: 6 | MSE: 21.757800048310777\n"
     ]
    }
   ],
   "source": [
    "for c in [1, 2, 3, 4, 5, 6]:\n",
    "    reg = make_pipeline(StandardScaler(), svm.SVR(C=c))\n",
    "    reg.fit(x_train, y_train)\n",
    "    y_pred = reg.predict(x_test)\n",
    "    mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "    print(\"Penalties: {} | MSE: {}\".format(c, mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalties: 1 | MSE: 16.694057583801456\n",
      "Penalties: 2 | MSE: 17.454989601610414\n",
      "Penalties: 3 | MSE: 13.994183218680243\n",
      "Penalties: 4 | MSE: 12.8215578839198\n",
      "Penalties: 5 | MSE: 14.113723560255737\n",
      "Penalties: 6 | MSE: 18.419417445034618\n"
     ]
    }
   ],
   "source": [
    "for max_depth in [1, 2, 3, 4, 5, 6]:\n",
    "    reg = XGBRegressor(max_depth=max_depth, objective=\"reg:squarederror\", verbosity=0)\n",
    "    reg.fit(x_train, y_train)\n",
    "    y_pred = reg.predict(x_test)\n",
    "    mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "    print(\"Penalties: {} | MSE: {}\".format(max_depth, mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
